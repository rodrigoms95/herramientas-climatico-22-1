{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrena un modelo de Gradient Boosted Trees\n",
    "# para predecir el consumo eléctrico\n",
    "# y la cantidad de usuarios.\n",
    "\n",
    "# Tomado y modificado a partir de:\n",
    "# https://www.datacamp.com/community/tutorials/xgboost-in-python\n",
    "# https://towardsdatascience.com/a-beginners-guide-to-xgboost-87f5d4c30ed7\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import ( mean_squared_error,\n",
    "    precision_score, recall_score, accuracy_score )\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_drive = \"/content/drive/MyDrive/Colab/\" \n",
    "path_data = path_drive + \"data/\"\n",
    "fname = \"data.csv\"\n",
    "\n",
    "data = pd.read_csv(path_data + fname)\n",
    "\n",
    "# Información utilizada para el modelo.\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Medias.\n",
    "data.iloc[:,2:].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desviaciones estándar.\n",
    "data.iloc[:,2:].std(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cuartiles.\n",
    "data.iloc[:,2:].quantile([0.25, 0.5, 0.75], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matriz de correlación de Pearson.\n",
    "data.iloc[:,2:].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escogemos el conjunto de features y de variables a predecir.\n",
    "# Escogemos solo uno de los conjuntos a predecir.\n",
    "i = 1\n",
    "X, Y = data.iloc[:,6:], data.iloc[:,i + 1]\n",
    "\n",
    "# Separamos en conjuntos de entrenamiento y de prueba.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    X, Y, test_size = 0.2, random_state = 123 )\n",
    "\n",
    "# Features a utilizar.\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable a predecir.\n",
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método 0.\n",
    "# Regresión lineal.\n",
    "\n",
    "# Creamos el regresor.\n",
    "lin_reg = LinearRegression()\n",
    "\n",
    "# Entrenamos el modelo.\n",
    "lin_reg.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluamos el modelo.\n",
    "preds = lin_reg.predict(X_test)\n",
    "\n",
    "# Calculamos el error.\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, preds))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Escoge las mejores predicciones ??????\n",
    "# ¿¿Por qué??\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "# Más medidas para evaluar el modelo.\n",
    "precision = precision_score(Y_test, best_preds, average='macro')\n",
    "recall = recall_score(Y_test, best_preds, average='macro')\n",
    "accuracy = accuracy_score(Y_test, best_preds)\n",
    "print(f\"Precision = {precision}\")\n",
    "print(f\"Recall = {recall}\")\n",
    "print(f\"Accuracy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método 1.\n",
    "# Entrenamiento simple.\n",
    "\n",
    "# Hiperparámetros.\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"colsample_bytree\": 0.3,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_depth\": 50,\n",
    "    #\"min_child_weight\" : 5,\n",
    "    \"alpha\": 10,\n",
    "    #\"gamma\": 0.2,\n",
    "    \"n_estimators\": 100,\n",
    "    \"tree_method\": \"gpu_hist\"\n",
    "    }\n",
    "\n",
    "# Creamos el regresor con los hiperparámetros.\n",
    "xg_reg = xgb.XGBRegressor( **params )\n",
    "\n",
    "# Entrenamos el modelo.\n",
    "xg_reg.fit(X_train, Y_train, verbose = True)\n",
    "\n",
    "# Evaluamos el modelo.\n",
    "preds = xg_reg.predict(X_test)\n",
    "\n",
    "# Calculamos el error.\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, preds))\n",
    "print(f\"RMSE: {rmse}\")\n",
    "\n",
    "# Escoge las mejores predicciones ??????\n",
    "# ¿¿Por qué??\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "# Más medidas para evaluar el modelo.\n",
    "precision = precision_score(Y_test, best_preds, average='macro')\n",
    "recall = recall_score(Y_test, best_preds, average='macro')\n",
    "accuracy = accuracy_score(Y_test, best_preds)\n",
    "print(f\"Precision = {precision}\")\n",
    "print(f\"Recall = {recall}\")\n",
    "print(f\"Accuracy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otras formas de entrenar el modelo\n",
    "\n",
    "Primero hacer funcionar la principal estrategia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método 2.\n",
    "# Ajuste de hiperparámetros.\n",
    "\n",
    "# Hiperparámetros.\n",
    "params = {\n",
    "    \"colsample_bytree\": [ 0.3, 0.4, 0.5 , 0.7 ],\n",
    "    \"learning_rate\": [0.05, 0.10, 0.15, 0.20, 0.25, 0.30],\n",
    "    \"max_depth\": [10, 20, 30, 40, 50, 60, 70],\n",
    "    #\"min_child_weight\" : [ 1, 3, 5, 7 ],\n",
    "    \"alpha\": [7, 8, 9, 10, 11, 12, 13],\n",
    "    #\"gamma\": [0.0, 0.1, 0.2 , 0.3, 0.4],\n",
    "    \"n_estimators\": [50, 100, 200, 300, 400, 500, 700],\n",
    "    }\n",
    "\n",
    "# Creamos el regresor.\n",
    "xg_reg = xgb.XGBRegressor(\n",
    "    objective = \"reg:squarederror\",\n",
    "    tree_method = \"gpu_hist\" )\n",
    "\n",
    "# Ajustador de hiperparámetros con Cross Validation.\n",
    "grid = GridSearchCV(xg_reg, params,\n",
    "    n_jobs = -1, cv = 5, verbose = 2\n",
    "    scoring = \"neg_mean_absolute_error\")\n",
    "\n",
    "# Entrenamos el modelo.\n",
    "grid.fit(X_train, Y_train)\n",
    "\n",
    "# Evaluamos el modelo.\n",
    "preds = grid.predict(X_test)\n",
    "\n",
    "# Calculamos el error.\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))\n",
    "\n",
    "# Escoge las mejores predicciones ??????\n",
    "# ¿¿Por qué??\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "# Más medidas para evaluar el modelo.\n",
    "print(\"Precision = {}\".format(precision_score(Y_test, best_preds, average='macro')))\n",
    "print(\"Recall = {}\".format(recall_score(Y_test, best_preds, average='macro')))\n",
    "print(\"Accuracy = {}\".format(accuracy_score(Y_test, best_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Método 3.\n",
    "# Cross Validation con XGBoost.\n",
    "\n",
    "# Hiperparámetros.\n",
    "params = {\n",
    "    \"objective\": \"reg:squarederror\",\n",
    "    \"colsample_bytree\": 0.3,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_depth\": 10,\n",
    "    #\"min_child_weight\" : 5,\n",
    "    \"alpha\": 10,\n",
    "    #\"gamma\": 0.2,\n",
    "    \"n_estimators\": 100,\n",
    "    \"tree_method\": \"gpu_hist\"\n",
    "    }\n",
    "\n",
    "# Ajustamos el DataFrame al formato de XGBoost.\n",
    "data_dmatrix = xgb.DMatrix(data = X, label = Y)\n",
    "\n",
    "# Realizamos el entrenamiento con Cross Validation.\n",
    "cv_results = xgb.cv(dtrain = data_dmatrix, params = params, nfold = 3,\n",
    "    num_boost_round = 50, early_stopping_rounds = 10, metrics = \"rmse\",\n",
    "    as_pandas = True, seed = 123)\n",
    "\n",
    "print((cv_results[\"test-rmse-mean\"]).tail(1))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
